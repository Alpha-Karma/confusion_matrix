
# üìä Avalia√ß√£o de Modelos de Classifica√ß√£o

Este projeto demonstra como calcular m√©tricas de avalia√ß√£o de desempenho de modelos de classifica√ß√£o
utilizando a **matriz de confus√£o**.

As m√©tricas implementadas s√£o:
- **Acur√°cia**
- **Precis√£o**
- **Sensibilidade (Recall)**
- **Especificidade**
- **F1-Score**

---

## üîé Matriz de Confus√£o

A matriz de confus√£o compara os **valores reais** com as **previs√µes** do modelo.

|                | Previsto Positivo | Previsto Negativo |
|----------------|------------------|------------------|
| **Real Positivo** | VP (Verdadeiro Positivo) ‚úÖ | FN (Falso Negativo) ‚ùå |
| **Real Negativo** | FP (Falso Positivo) ‚ùå | VN (Verdadeiro Negativo) ‚úÖ |

- **VP (True Positive)** ‚Üí O modelo disse "positivo" e era positivo.  
- **VN (True Negative)** ‚Üí O modelo disse "negativo" e era negativo.  
- **FP (False Positive)** ‚Üí O modelo disse "positivo" mas era negativo.  
- **FN (False Negative)** ‚Üí O modelo disse "negativo" mas era positivo.  

---

## üìê F√≥rmulas das M√©tricas

- **Acur√°cia** = (VP + VN) / (VP + VN + FP + FN)  
- **Precis√£o** = VP / (VP + FP)  
- **Recall (Sensibilidade)** = VP / (VP + FN)  
- **Especificidade** = VN / (VN + FP)  
- **F1-Score** = 2 √ó (Precis√£o √ó Recall) / (Precis√£o + Recall)  

---

## üìÇ Estrutura do Reposit√≥rio

- `Metrics_Code.ipynb` ‚Üí Notebook com o c√≥digo organizado.  
- `README.md` ‚Üí Arquivo explicativo com teoria e instru√ß√µes.  

---

## ‚ñ∂Ô∏è Como Executar

1. Clone este reposit√≥rio:
   ```bash
   git clone https://github.com/seu-usuario/seu-repo.git
   cd seu-repo
   ```

2. Abra o Jupyter Notebook ou Google Colab.

3. Execute o arquivo:
   ```bash
   jupyter notebook Metrics_Code.ipynb
   ```

---

## ‚úÖ Exemplo de Sa√≠da

O c√≥digo gera:
- A matriz de confus√£o plotada com **Seaborn**.  
- As m√©tricas calculadas no console.

Exemplo de sa√≠da esperada:

```
Acur√°cia: 0.87
Precis√£o: 0.86
Recall (Sensibilidade): 0.85
Especificidade (m√©dia): 0.90
F1-Score: 0.85
```

---

‚úçÔ∏è Autor: *KARMA*
